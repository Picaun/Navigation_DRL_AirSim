[options]
env_name = NH_center
dynamic_name = Multirotor
navigation_3d = True
using_velocity_state = True
perception = depth
algo = PPO
policy_name = CNN_FC
net_arch = [256, 128]
activation_function = relu
cnn_feature_num = 64
keyboard_debug = False
generate_q_map = True
q_map_save_steps = 10000
use_wandb = False
total_timesteps = 200000

[wandb]
name = SimpleAvoid-3D-CNN-PPO
notes = Training with PPO algorithm

[environment]
max_depth_meters = 15
screen_height = 60
screen_width = 90
reward_type = reward_hybrid
crash_penalty = -1.0
crash_distance = 2
accept_radius = 2
distance_weight = -0.01
max_episode_steps = 800

[DRL]
gamma = 0.995
learning_rate = 2.5e-4
n_steps = 1024
batch_size = 64
n_epochs = 4
ent_coef = 0.01
clip_range = 0.2
max_grad_norm = 0.8

[policy_config]
cnn_dropout = 0.1
fc_init_scale = 0.3
use_batch_norm = True

[multirotor]
dt = 0.1
acc_xy_max = 2.0
v_xy_max = 5
v_xy_min = 0.5
v_z_max = 2.0
yaw_rate_max_deg = 30.0